# Gemini LLM Application

Gemini LLM Application is a web-based interface designed for interacting with a large language model (LLM). This application allows users to input questions and receive responses generated by the LLM.

## Features

- **User-Friendly Interface**: Simple and intuitive design for easy interaction.
- **Input Field**: Enter your question in the provided input field.
- **Ask the Question**: Submit your query by clicking the "Ask the question" button.
- **Deployment**: The application is ready for deployment and can be accessed via a web browser.

## Project Structure

```
GeminiLLMAPP/
│
├── venv/               # Virtual environment directory
├── requirements.txt    # Python dependencies
├── .env                # Environment variables file
├── app.py              # Main application script
└── vision.py           # Vision-related functionalities
```

## Getting Started

### Prerequisites

To run this application, you will need:

- Python 3.10
- Streamlit
- An LLM model (e.g.,Google-generativeai)
- python-dotenv
- Necessary dependencies (listed in `requirements.txt`)

### Installation

1. Clone the repository:

```bash
git clone https://github.com/Gangatharangurusamy/Gemini-LLM-Application.git
cd gemini-llm-application
```

2. Create and activate a virtual environment:

```bash
python -m venv venv
source venv/bin/activate   # On Windows, use `venv\Scripts\activate`
```

3. Install the required dependencies:

```bash
pip install -r requirements.txt
```

4. Set up the environment variables by creating a `.env` file in the root directory and adding necessary configurations. For example:

```
API_KEY=your_api_key
OTHER_CONFIG=your_other_config
```

### Running the Application

To start the main application, use the following command:

```bash
streamlit run app.py
```

This will launch the application, and you can access it in your web browser at `http://localhost:8501`.

To start the vision-related functionalities, use the following command:

```bash
streamlit run vision.py
```

This will launch the vision application, and you can access it in your web browser at `http://localhost:8501`.

## Usage

1. Open your web browser and navigate to `http://localhost:8501`.
2. Enter your question in the input field.
3. Click on the "Ask the question" button.
4. The response from the LLM will be displayed on the screen.

## Deployment

### Deployment on Streamlit Cloud

Streamlit provides an easy way to deploy applications on their cloud platform. Follow these steps to deploy your application:

1. Push your code to a GitHub repository.

2. Go to [Streamlit Cloud](https://gangaguru-gemini-llm-app-textdata.streamlit.app/) and sign in with your GitHub account.

3. Click on "New app" and select the repository and branch you want to deploy.

4. Specify the main file (`app.py`) in the "Main file path" field.

5. Click "Deploy".

6. To deploy `vision.py`, repeat steps 3-5 but specify `vision.py` as the main file.

7. Go to [Streamlit Cloud](https://gangaguru-gemini-llm-app.streamlit.app/) and sign in with your GitHub account. 


## Contact

If you have any questions or suggestions, please feel free to contact us at [gangatharan0401@gmail.com].

---
